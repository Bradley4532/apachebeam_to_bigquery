{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project: Import csv to bigquery table\n",
    "#StartDate: 4/06/2022\n",
    "#EndDate: \n",
    "#Developer: Bradley, Hongquy, Khoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,render_template,request,redirect,url_for\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import os, re, datetime, uuid\n",
    "import apache_beam as beam\n",
    "import argparse\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from werkzeug.utils import secure_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to allow a authenticated user on the project to work on bigquerry\n",
    "Key_path = r\"C:\\\\Users\\Brad\\Documents\\model-craft-342921-ea36cdb339e7.json\"\n",
    "\n",
    "#this is needed to request a job\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = Key_path\n",
    "credentials = service_account.Credentials.from_service_account_file(Key_path,scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "client=bigquery.Client(credentials=credentials,project=credentials.project_id)\n",
    "#table_id='model-craft-342921.testing.Task3'\n",
    "storage_client=storage.Client(credentials=credentials,project=credentials.project_id)\n",
    "bucket = storage_client.get_bucket(\"data_intake4062022\")\n",
    "\n",
    "job_name = 'pythontobigquerry-{}'.format(uuid.uuid4())\n",
    "\n",
    "beam_options = PipelineOptions(\n",
    "                            runner = 'DataflowRunner',\n",
    "                            project = 'model-craft-342921',\n",
    "                            job_name = '{}'.format(job_name),\n",
    "                            temp_location = 'gs://data_intake4062022/temp1',\n",
    "                            region='us-east1',\n",
    "                            service_account_email = 'practice-py@model-craft-342921.iam.gserviceaccount.com'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterRecord(beam.DoFn):\n",
    "    def process(self, element, table_sch):\n",
    "        import apache_beam as beam\n",
    "        flag = 0\n",
    "        error = ''\n",
    "        if(len(element) > len(table_sch)):\n",
    "            flag = 1\n",
    "            error = 'There are too many columns. Expected {} columns, not {}'.format(len(table_sch),len(element))\n",
    "        else:\n",
    "            for x in range(0, len(element)):\n",
    "                #print(table_sch[x]['type'])\n",
    "                if(table_sch[x]['type'] == 'STRING'):\n",
    "                    if(element[x].strip().isalpha() == False):\n",
    "                        #flag = 1\n",
    "                        #error = 'Expected string not int data type in column {}'.format(table_sch[x]['name'])\n",
    "                        pass\n",
    "                    else:\n",
    "                        pass\n",
    "                elif(table_sch[x]['type'] == 'INTEGER'):\n",
    "                    if(element[x].strip().isalpha()):\n",
    "                        flag = 1\n",
    "                        error = 'Expected int not string data type in column: {}'.format(table_sch[x]['name'])\n",
    "                    elif('.' in element[x]):\n",
    "                        flag = 1\n",
    "                        error = 'Expected int not float data type in column: {}'.format(table_sch[x]['name'])\n",
    "                    else:\n",
    "                        pass\n",
    "                elif(table_sch[x]['type'] == 'FLOAT'):\n",
    "                    if(element[x].strip().isalpha()):\n",
    "                        flag = 1\n",
    "                        error = 'Expected float not string data type in column: {}'.format(table_sch[x]['name'])\n",
    "                    elif('.' in element[x] == False):\n",
    "                        flag = 1\n",
    "                        error = 'Expected float not int data type in column: {}'.format(table_sch[x]['name'])\n",
    "                    else:\n",
    "                        pass\n",
    "                if(table_sch[x]['mode'] == 'REQUIRED'):\n",
    "                        if(len(element[x]) == 0):\n",
    "                            flag = 1\n",
    "                            error = 'Null in required column: {}'.format(table_sch[x]['name'])\n",
    "        if(flag == 0):\n",
    "            yield beam.pvalue.TaggedOutput('Good', element)\n",
    "            yield beam.pvalue.TaggedOutput('Tgood', 1)\n",
    "        else:\n",
    "            error_log = \"\"\"| Error Message - {} || Inputted Data - {} |\\n\"\"\".format(error, element)\n",
    "            yield beam.pvalue.TaggedOutput('Bad', error_log)\n",
    "            yield beam.pvalue.TaggedOutput('Tbad', 1)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class formating(beam.DoFn):\n",
    "    def process(self, element, table_sch):\n",
    "        import apache_beam as beam\n",
    "        record = {}\n",
    "        for x in range(0, len(element)):\n",
    "            name = table_sch[x]['name']\n",
    "            if(table_sch[x]['type'] == 'STRING'):\n",
    "                record[name] = str(element[x])\n",
    "            elif(table_sch[x]['type'] == 'INTEGER'):\n",
    "                record[name] = int(element[x])\n",
    "            elif(table_sch[x]['type'] == 'FLOAT'):\n",
    "                record[name] = float(element[x])\n",
    "        yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class converter(beam.DoFn):\n",
    "    def process(self, element, total_records, job_name,countBad):\n",
    "        import apache_beam as beam\n",
    "        record = {}\n",
    "        record[Project_id] = str(job_name)\n",
    "        record[Total_records] = int(total_records)\n",
    "        record[Total_good_records] = int(element)\n",
    "        record[Total_bad_records] = int(countBad)\n",
    "        yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is needed to run the website html\n",
    "app = Flask(__name__)\n",
    "\n",
    "#secret key is to allow this python code to move variable from the frontend to the backend\n",
    "app.secret_key = \"35367565\"\n",
    "\n",
    "@app.route('/')\n",
    "def form():\n",
    "    return redirect(url_for('upload'))\n",
    "\n",
    "#This will render the frontend of the website to get the json file\n",
    "@app.route('/upload', methods=['GET','POST'])\n",
    "def upload():\n",
    "\n",
    "    #resets the message so that previous messages dont confuse the user\n",
    "    message = None\n",
    "    \n",
    "    tables = ['Task3'] #change--------------------------\n",
    "    \n",
    "    #This will only run if the user attempts to submit a file\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        #this will only run if what the user submitted is a file\n",
    "        if 'file' in request.files:\n",
    "            #this gets the file data\n",
    "            file = request.files['file']\n",
    "            #this aquires the name of the file\n",
    "            filename = secure_filename(file.filename)\n",
    "            if len(file.readlines()) == 0:\n",
    "                message = \"File has no data to process\"\n",
    "            else:\n",
    "                file.seek(0)\n",
    "                try:\n",
    "                    #this will only run if the file is a csv\n",
    "                    if filename.endswith('.csv'):\n",
    "                        blob = bucket.blob('data.csv')\n",
    "                        blob.upload_from_file(file)\n",
    "                        \n",
    "                        file.seek(0)\n",
    "                        total_records = file.readlines()\n",
    "                        \n",
    "                        table_id = request.form.getlist('checks')[0]\n",
    "                        SCHEMA = {}\n",
    "                        table_sch = []\n",
    "                        try:\n",
    "                            SchemaJob = client.get_table('model-craft-342921.testing.{}'.format(table_id))\n",
    "                            for s in SchemaJob.schema:\n",
    "                                new_dict = {}\n",
    "                                new_dict['name'] = s.name\n",
    "                                new_dict['type'] = s.field_type\n",
    "                                new_dict['mode'] = s.mode\n",
    "                                table_sch.append(new_dict)\n",
    "                            SCHEMA['fields'] = table_sch\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                        \n",
    "                        filename = \"LOG: \"+ str(datetime.datetime.now()) + \".txt\"\n",
    "                        try:\n",
    "                            p = beam.Pipeline(options=beam_options)\n",
    "                            good, bad, Tgood, Tbad = (p | 'ReadData' >> beam.io.ReadFromText('gs://data_intake4062022/data.csv', skip_header_lines =1)\n",
    "                                   | 'Split' >> beam.Map(lambda x: x.split(','))\n",
    "                                    | 'Filter' >> beam.ParDo(FilterRecord(),table_sch).with_outputs(\"Good\", \"Bad\",\"Tgood\",\"Tbad\")\n",
    "                                        )\n",
    "                            countBad = (Tbad | 'Count Bad records' >> beam.combiners.Count.Globally()\n",
    "                            )\n",
    "                            (Tgood | 'Count Good records' >> beam.combiners.Count.Globally()\n",
    "                                    | 'format to dict1' >> beam.ParDo(converter(),total_records, job_name, beam.pvalue.AsSingleton(countBad))\n",
    "                                     | 'WriteToBigQuery1' >> beam.io.WriteToBigQuery(\n",
    "                                       'model-craft-342921:testing.Statics',\n",
    "                                       schema=SCHEMA,\n",
    "                                       write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "                            )\n",
    "                            (good | 'format to dict2' >> beam.ParDo(formating(),table_sch) \n",
    "                                   | 'WriteToBigQuery2' >> beam.io.WriteToBigQuery(\n",
    "                                       'model-craft-342921:testing.{}'.format(table_id),\n",
    "                                       schema='Project_id:STRING,Total_records:INTEGER,Total_good_records:INTEGER,Total_bad_records:INTEGER,Completion_time:STRING',\n",
    "                                       write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "                                    )\n",
    "                            (bad | 'log bad records' >> beam.io.WriteToText('gs://practice_error_logs/{}'.format(filename), shard_name_template = \"\")\n",
    "                                    )\n",
    "                            result = p.run()\n",
    "                            result.wait_until_finish()\n",
    "                            message = \"Data uploaded to the Bigquery\"\n",
    "                        except Exception as error:\n",
    "                            print('This was the error: ', error)\n",
    "                            message = \"Error setting up the pipeline\"\n",
    "\n",
    "\n",
    "                    #If the file is not a json or the csv this will run\n",
    "                    else:\n",
    "                        message = \"File type is not excepted\"\n",
    "                    #endif\n",
    "                except Exception as error:\n",
    "                    print('This was the error: ', error)\n",
    "                    message = \"There was an error in creating the request\"\n",
    "            #endif\n",
    "        #This will run if the submition is not a file type\n",
    "        elif 'file' not in request.files:\n",
    "            message = \"There was no file to upload\"\n",
    "        #endif\n",
    "    #endif\n",
    "\n",
    "    #this will render the template on the website\n",
    "    return render_template(\"front.html\", message = message, tables = tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 14:41:03] \"\u001b[32mGET / HTTP/1.1\u001b[0m\" 302 -\n",
      "INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 14:41:03] \"\u001b[37mGET /upload HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\apache_beam\\io\\gcp\\bigquery.py:2138: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  is_streaming_pipeline = p.options.view_as(StandardOptions).streaming\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\apache_beam\\io\\gcp\\bigquery_file_loads.py:1128: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = p.options.view_as(GoogleCloudOptions).temp_location\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-61f385fa-7ce1-42f1-891e-1c56da8006b5.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-61f385fa-7ce1-42f1-891e-1c56da8006b5.json']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
