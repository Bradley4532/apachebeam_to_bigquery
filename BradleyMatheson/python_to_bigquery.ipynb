{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project: Import csv to bigquery table\n",
    "#StartDate: 4/06/2022\n",
    "#EndDate: \n",
    "#Developer: Bradley Matheson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,render_template,request\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import os, re\n",
    "import apache_beam as beam\n",
    "import argparse\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from werkzeug.utils import secure_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is needed to run the website html\n",
    "app = Flask(__name__)\n",
    "\n",
    "#secret key is to allow this python code to move variable from the frontend to the backend\n",
    "app.secret_key = \"35367565\"\n",
    "\n",
    "#this is to allow a authenticated user on the project to work on bigquerry\n",
    "Key_path = r\"C:\\\\Users\\Brad\\Documents\\model-craft-342921-ea36cdb339e7.json\"\n",
    "\n",
    "#this is needed to request a job\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = Key_path\n",
    "credentials = service_account.Credentials.from_service_account_file(Key_path,scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "client=bigquery.Client(credentials=credentials,project=credentials.project_id)\n",
    "table_id='model-craft-342921.testing.Task2'\n",
    "storage_client=storage.Client(credentials=credentials,project=credentials.project_id)\n",
    "bucket = storage_client.get_bucket(\"data_intake4062022\")\n",
    "#SCHEMA = 'name:STRING,id:INTEGER,salary_in_k:FLOAT,phonenumber:STRING'\n",
    "SCHEMA = {\n",
    "    'fields' : [\n",
    "                {'name' : 'name', 'type' : 'STRING', 'mode' : 'REQUIRED'},\n",
    "                {'name' : 'id', 'type' : 'INTEGER', 'mode' : 'REQUIRED'},\n",
    "                {'name' : 'salary_in_k', 'type' : 'FLOAT', 'mode' : 'REQUIRED'},\n",
    "                {'name' : 'phonenumber', 'type' : 'STRING', 'mode' : 'REQUIRED'}\n",
    "               ]\n",
    "}\n",
    "beam_options = PipelineOptions(\n",
    "                            runner = 'DataflowRunner',\n",
    "                            project = 'model-craft-342921',\n",
    "                            job_name = 'pythontobigquerry',\n",
    "                            temp_location = 'gs://data_intake4062022/temp1',\n",
    "                            region='us-east1',\n",
    "                            service_account_email = 'practice-py@model-craft-342921.iam.gserviceaccount.com'\n",
    "                        )\n",
    "#input_path = 'gs://dataflow_example41622/data_intake'\n",
    "\n",
    "class FilterRecord(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        import apache_beam as beam\n",
    "        flag = 0\n",
    "        for x in range(0, len(element)):\n",
    "            if(element[x] == element[0]):\n",
    "                if(element[x].strip().isalpha() == False):\n",
    "                    flag = 1\n",
    "                elif(len(element[x]) == 0):\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    pass\n",
    "            elif(element[x] == element[1]):\n",
    "                if(element[x].strip().isalpha()):\n",
    "                    flag = 1\n",
    "                elif('.' in element[x]):\n",
    "                    flag = 1\n",
    "                elif(len(element[x]) == 0):\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    pass\n",
    "            elif(element[x] == element[2]):\n",
    "                if(element[x].strip().isalpha()):\n",
    "                    flag = 1\n",
    "                elif('.' in element[x] == False):\n",
    "                    flag = 1\n",
    "                elif(len(element[x]) == 0):\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    pass\n",
    "            elif(element[x] == element[3]):\n",
    "                if(element[x].strip().isalpha() == False):\n",
    "                    flag = 1\n",
    "                elif(len(element[x]) == 0):\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "        if(flag == 0):\n",
    "            yield beam.pvalue.TaggedOutput('Good', element)\n",
    "        else:\n",
    "            yield beam.pvalue.TaggedOutput('Bad', element)\n",
    "\n",
    "\n",
    "\n",
    "def discard_incomplete(data):\n",
    "    \"\"\"Filters out records that don't have an information.\"\"\"\n",
    "    return len(data['name']) > 0 and len(data['id']) > 0 and len(data['salary_in_k']) > 0 and len(data['phonenumber']) > 0\n",
    "\n",
    "def convert_types(data):\n",
    "    \"\"\"Converts string values to their appropriate type.\"\"\"\n",
    "    data['name'] = str(data['name']) if 'name' in data else None\n",
    "    data['id'] = int(data['id']) if 'id' in data else None\n",
    "    data['salary_in_k'] = float(data['salary_in_k']) if 'salary_in_k' in data else None\n",
    "    data['phonenumber'] = str(data['phonenumber']) if 'phonenumber' in data else None\n",
    "    return data\n",
    "\n",
    "def get_error_report(errors, file_dataframe):\n",
    "    report = []\n",
    "    isNull = False\n",
    "    nullIndex = 0\n",
    "    column_Names = [\"name\",\"id\",\"salary_in_k\",\"phonenumber\"]\n",
    "    try:\n",
    "        for error_index, error in enumerate(errors):\n",
    "            error_location = re.findall(r'\\d+', error['message'])\n",
    "            message = error['message']\n",
    "            try:\n",
    "                error_value = re.findall(r\"'(.*?)'\", error['message'])[0]\n",
    "                found_error_records = file_dataframe[file_dataframe.isin([error_value]).any(axis=1)].values\n",
    "                error_message = message.replace(\"field id (position {}) starting at location {}\".format(error_location[-2],error_location[-1]),\"\"\"column '{}'\"\"\".format(column_Names[int(error_location[-2])]))\n",
    "            except:\n",
    "                #found_error_records = 'null'\n",
    "                # Get all the rows containing null values in required columns and get their row numbers\n",
    "                found_error_records = file_dataframe[file_dataframe.isna().any(axis=1)].values\n",
    "                error_message = message.replace(\"index: {} is missing in row starting at position: {}\".format(error_location[-2],error_location[-1]),\"\"\"'{}'\"\"\".format(column_Names[int(error_location[-2])]))\n",
    "                isNull = True\n",
    "            if isNull:\n",
    "                found_error_records = found_error_records[nullIndex]\n",
    "                nullIndex+=1\n",
    "                isNull = False\n",
    "            log_string = \"\"\"| Error # - {} || Error Message - {} || Inputted Data - {} |\"\"\".format(error_index, error_message, found_error_records)\n",
    "            report.append(log_string)\n",
    "    except:\n",
    "        raise\n",
    "    #return str(report)\n",
    "    return report\n",
    "\n",
    "\n",
    "#This will render the frontend of the website to get the json file\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "def index():\n",
    "\n",
    "    #resets the message so that previous messages dont confuse the user\n",
    "    message = None\n",
    "\n",
    "    empty = False\n",
    "\n",
    "    #This will only run if the user attempts to submit a file\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        #this will only run if what the user submitted is a file\n",
    "        if 'file' in request.files:\n",
    "\n",
    "            #this gets the file data\n",
    "            file = request.files['file']\n",
    "            #this aquires the name of the file\n",
    "            filename = secure_filename(file.filename)\n",
    "            if filename.endswith('.csv'):\n",
    "\n",
    "                #this will only run if the file is a csv\n",
    "                if filename.endswith('.csv'):\n",
    "                    blob = bucket.blob('data.csv')\n",
    "                    blob.upload_from_file(file)\n",
    "                    #bucket = storage_client.get_bucket(\"practice_error_logs\")\n",
    "                    #filename = \"LOG: \"+ str(datetime.datetime.now()) + \".txt\"\n",
    "                    try:\n",
    "                        p = beam.Pipeline(options=beam_options)\n",
    "                        good, bad = (p | 'ReadData' >> beam.io.ReadFromText('gs://data_intake4062022/data.csv', skip_header_lines =1)\n",
    "                               | 'Split' >> beam.Map(lambda x: x.split(','))\n",
    "                                | 'Filter' >> beam.ParDo(FilterRecord()).with_outputs(\"Good\", \"Bad\")\n",
    "                                    )\n",
    "                        (good | 'format to dict' >> beam.Map(lambda x: {\"name\": str(x[0]), \"id\": int(x[1]), \"salary_in_k\": float(x[2]), \"phonenumber\": str(x[3])}) \n",
    "                               #| 'DelIncompleteData' >> beam.Filter(discard_incomplete)\n",
    "                               #| 'Convertypes' >> beam.Map(convert_types)\n",
    "                               | 'WriteToBigQuery' >> beam.io.WriteToBigQuery(\n",
    "                                   '{0}:testing.Task3'.format(credentials.project_id),\n",
    "                                   schema=SCHEMA,\n",
    "                                   write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "                                )\n",
    "                        (bad | 'log bad records' >> beam.io.WriteToText('gs://practice_error_logs/Bad.csv', shard_name_template = \"\")\n",
    "                                )\n",
    "                        result = p.run()\n",
    "                        message = \"Data uploaded to the Bigquery\"\n",
    "                    except Exception as error:\n",
    "                        print('This was the error: ', error)\n",
    "                        message = \"Error setting up the pipeline\"\n",
    "                    \n",
    "    \n",
    "            #If the file is not a json or the csv this will run\n",
    "            else:\n",
    "                message = \"File type is not excepted\"\n",
    "            #endif\n",
    "\n",
    "        #This will run if the submition is not a file type\n",
    "        elif 'file' not in request.files:\n",
    "            message = \"There was no file to upload\"\n",
    "        #endif\n",
    "    #endif\n",
    "\n",
    "    #this will render the template on the website\n",
    "    return render_template(\"front.html\", message = message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Apr/2022 13:40:56] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\apache_beam\\io\\gcp\\bigquery.py:2138: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  is_streaming_pipeline = p.options.view_as(StandardOptions).streaming\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\apache_beam\\io\\gcp\\bigquery_file_loads.py:1128: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  temp_location = p.options.view_as(GoogleCloudOptions).temp_location\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-b0cb084b-fbc5-45e4-a5b2-f23ef6af0f75.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-b0cb084b-fbc5-45e4-a5b2-f23ef6af0f75.json']\n",
      "INFO:werkzeug:127.0.0.1 - - [08/Apr/2022 13:41:27] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with beam.Pipeline(options=beam_options) as pipeline:\n",
    "                            records = (\n",
    "                                pipeline\n",
    "                                | beam.io.ReadFromText('gs://data_intake4062022/data.csv', skip_header_lines = True)\n",
    "                                | beam.Map(lambda x : x.split(\",\"))\n",
    "                                | beam.Map(lambda x: {\"name\": x[0], \"id\": x[1], \"salary_in_k\": x[2], \"phonenumber\": x[3]})\n",
    "                                | beam.io.WriteToBigQuery('{0}:testing.Task3'.format(credentials.project_id), schema=SCHEMA, write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "                                \n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
