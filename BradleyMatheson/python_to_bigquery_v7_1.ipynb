{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project: Import csv to bigquery table\n",
    "#StartDate: 4/06/2022\n",
    "#EndDate: \n",
    "#Developer: Bradley, Hongquy, Khoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,render_template,request,redirect,url_for\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import os, re, datetime, uuid, time, json\n",
    "import google.cloud.logging\n",
    "import apache_beam as beam\n",
    "from io import StringIO\n",
    "import argparse\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from werkzeug.utils import secure_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to allow a authenticated user on the project to work on bigquerry\n",
    "Key_path = r\"C:\\\\Users\\Brad\\Documents\\model-craft-342921-ea36cdb339e7.json\"\n",
    "\n",
    "#this is needed to request a job\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = Key_path\n",
    "credentials = service_account.Credentials.from_service_account_file(Key_path,scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "client=bigquery.Client(credentials=credentials,project=credentials.project_id)\n",
    "#table_id='model-craft-342921.testing.Task3'\n",
    "storage_client=storage.Client(credentials=credentials,project=credentials.project_id)\n",
    "bucket = storage_client.get_bucket(\"data_intake4062022\")\n",
    "bucket1 = storage_client.get_bucket(\"error_messages4142022\")\n",
    "bucket2 = storage_client.get_bucket(\"practice_error_logs\")\n",
    "client1 = google.cloud.logging.Client()\n",
    "logger = client1.logger(name=\"dataflow.googleapis.com%2Fworker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import json, re\n",
    "blob = bucket2.blob('LOG: 2022-04-15 15:48:41.064521.txt')\n",
    "downloaded_blob = blob.download_as_string()\n",
    "log_message = downloaded_blob.decode(\"utf-8\", \"ignore\")\n",
    "log_message =log_message.split('\\n')\n",
    "bad_row = []\n",
    "bad_json = []\n",
    "result = {}\n",
    "for element in log_message:\n",
    "    element = element.replace(\"'model-craft-342921:testing.Task3', \",'')\n",
    "    element = element.replace('(','')\n",
    "    element = element.replace(')','')\n",
    "    element = element.replace(\"'\",'\"')\n",
    "    bad_row.append(element)\n",
    "for index in range(0,len(bad_row)-1):\n",
    "    bad_json.append(json.loads(bad_row[index]))\n",
    "result['elements'] = bad_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import json, re\n",
    "blob = bucket1.blob('LOG: 2022-04-15 15:48:41.064521.txt')\n",
    "downloaded_blob = blob.download_as_string()\n",
    "log_message = downloaded_blob.decode(\"utf-8\", \"ignore\")\n",
    "log_message = log_message.replace(\"'\",'\"')\n",
    "bad_message = json.loads(log_message)\n",
    "result1 = {}\n",
    "result1['elements'] = bad_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bad_rows = []\n",
    "count = 0\n",
    "for rec in result1['elements']:\n",
    "    for input_data in result['elements']:\n",
    "        message = ''\n",
    "        if input_data[rec['location']] == rec['message'].split(': ')[1]:\n",
    "            message = 'Error #{} - Message: {} in column {} - Input: {}'.format(count, rec['message'],rec['location'],input_data)\n",
    "            count += 1\n",
    "            result['elements'].remove(input_data)\n",
    "            final_bad_rows.append(message)\n",
    "\n",
    "            \n",
    "for p in final_bad_rows:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter_str = (\n",
    "    f'resource.labels.job_name=pythontobigquerry-26828c6d-9c18-4fd4-a010-aec4cd47f78f'\n",
    "    f' resource.type=\"dataflow_step\"'\n",
    "    f' AND severity >= ERROR'\n",
    ")\n",
    "messages = []\n",
    "log_builder = {}\n",
    "for entry in logger.list_entries(filter_=filter_str):  # API call(s)\n",
    "    message = entry.to_api_repr()['jsonPayload']['message']\n",
    "    list_extract = message.replace(\"There were errors inserting to BigQuery. Will not retry. Errors were \",\"\")\n",
    "    list_extract = list_extract.replace(\"'\",'\"')\n",
    "    res = json.loads(list_extract)\n",
    "    for i in range(0,len(res)):\n",
    "        log_builder = {}\n",
    "        log_builder['location'] = res[i]['errors'][0]['location']\n",
    "        log_builder['message'] = res[i]['errors'][0]['message']\n",
    "        messages.append(log_builder)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class formating(beam.DoFn):\n",
    "    def process(self, element, table_sch):\n",
    "        import apache_beam as beam\n",
    "        record = {}\n",
    "        for x in range(0, len(element)):\n",
    "            name = table_sch[x]['name']\n",
    "            record[name] = element[x]\n",
    "        yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_message(beam.DoFn):\n",
    "    def process(self, element, bad_input_data):\n",
    "        import apache_beam as beam\n",
    "        from io import StringIO\n",
    "        import json, re\n",
    "        count = 0\n",
    "        for input_data in bad_input_data['elements']:\n",
    "            message = ''\n",
    "            if input_data[element['location']] == element['message'].split(': ')[1]:\n",
    "                message = 'Error #{} - Message: {} in column {} - Input: {}'.format(count, element['message'],element['location'],input_data)\n",
    "                count += 1\n",
    "                bad_input_data['elements'].remove(input_data)\n",
    "                yield message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-a37664fc-f0dc-40f1-a2b7-7b49ddc7ddaa.json']\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-a37664fc-f0dc-40f1-a2b7-7b49ddc7ddaa.json']\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', 'C:\\\\Users\\\\Brad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-a37664fc-f0dc-40f1-a2b7-7b49ddc7ddaa.json']\n"
     ]
    }
   ],
   "source": [
    "filename = 'LOG: 2022-04-15 15:48:41.064521.txt'\n",
    "job_name = 'pythontobigquerry-{}'.format(uuid.uuid4())\n",
    "beam_options = PipelineOptions(\n",
    "                            runner = 'DataflowRunner',\n",
    "                            #runner='DirectRunner',\n",
    "                            project = 'model-craft-342921',\n",
    "                            job_name = '{}'.format(job_name),\n",
    "                            temp_location = 'gs://data_intake4062022/temp1',\n",
    "                            region='us-east1',\n",
    "                            service_account_email = 'practice-py@model-craft-342921.iam.gserviceaccount.com'\n",
    "                        )\n",
    "try:\n",
    "    p1 = beam.Pipeline(options=beam_options)\n",
    "    events  = (p1 | 'ReadData' >> beam.io.ReadFromText('gs://practice_error_logs/{}'.format(filename))\n",
    "                    | 'Store Final Message' >> beam.io.WriteToText('gs://complete_message_4182022/{}'.format(filename), shard_name_template = \"\")\n",
    "              )\n",
    "    result = p1.run()\n",
    "    result.wait_until_finish()\n",
    "\n",
    "except Exception as error:\n",
    "    print('This was the error: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'LOG: 2022-04-15 15:48:41.064521.txt'\n",
    "job_name = 'pythontobigquerry-{}'.format(uuid.uuid4())\n",
    "try:\n",
    "    blob = bucket2.blob(filename)\n",
    "    downloaded_blob = blob.download_as_string()\n",
    "    log_message = downloaded_blob.decode(\"utf-8\", \"ignore\")\n",
    "    log_message =log_message.split('\\n')\n",
    "    bad_row = []\n",
    "    bad_json = []\n",
    "    bad_input_data = {}\n",
    "    for element in log_message:\n",
    "        element = element.replace(\"'model-craft-342921:testing.Task3', \",'')\n",
    "        element = element.replace('(','')\n",
    "        element = element.replace(')','')\n",
    "        element = element.replace(\"'\",'\"')\n",
    "        bad_row.append(element)\n",
    "    for index in range(0,len(bad_row)-1):\n",
    "        bad_json.append(json.loads(bad_row[index]))\n",
    "    bad_input_data['elements'] = bad_json\n",
    "\n",
    "except Exception as error:\n",
    "    print('This was the error: ', error)\n",
    "    message = \"Error setting up messaging\"\n",
    "    \n",
    "beam_options = PipelineOptions(\n",
    "                            runner = 'DataflowRunner',\n",
    "                            #runner='DirectRunner',\n",
    "                            project = 'model-craft-342921',\n",
    "                            job_name = '{}'.format(job_name),\n",
    "                            temp_location = 'gs://data_intake4062022/temp1',\n",
    "                            region='us-east1',\n",
    "                            service_account_email = 'practice-py@model-craft-342921.iam.gserviceaccount.com'\n",
    "                        )\n",
    "try:\n",
    "    p1 = beam.Pipeline(options=beam_options)\n",
    "    events  = (p1 | 'ReadData' >> beam.io.ReadFromText('gs://error_messages4142022/{}'.format(filename))\n",
    "                  | 'Process Messaging' >> beam.ParDo(process_message(),bad_input_data)\n",
    "                    | 'Store Final Message' >> beam.io.WriteToText('gs://complete_message_4182022/{}'.format(filename), shard_name_template = \"\")\n",
    "              )\n",
    "    result = p1.run()\n",
    "    result.wait_until_finish()\n",
    "\n",
    "except Exception as error:\n",
    "    print('This was the error: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is needed to run the website html\n",
    "app = Flask(__name__)\n",
    "\n",
    "#secret key is to allow this python code to move variable from the frontend to the backend\n",
    "app.secret_key = \"35367565\"\n",
    "\n",
    "@app.route('/')\n",
    "def form():\n",
    "    return redirect(url_for('upload'))\n",
    "\n",
    "#This will render the frontend of the website to get the json file\n",
    "@app.route('/upload', methods=['GET','POST'])\n",
    "def upload():\n",
    "\n",
    "    #resets the message so that previous messages dont confuse the user\n",
    "    message = None\n",
    "    \n",
    "    tables = ['Task3'] #change--------------------------\n",
    "    \n",
    "    job_name = 'pythontobigquerry-{}'.format(uuid.uuid4())\n",
    "\n",
    "    beam_options = PipelineOptions(\n",
    "                                runner = 'DataflowRunner',\n",
    "                                #runner='DirectRunner',\n",
    "                                project = 'model-craft-342921',\n",
    "                                job_name = '{}'.format(job_name),\n",
    "                                temp_location = 'gs://data_intake4062022/temp1',\n",
    "                                region='us-east1',\n",
    "                                maxNumWorkers= 1,\n",
    "                                service_account_email = 'practice-py@model-craft-342921.iam.gserviceaccount.com'\n",
    "                            )\n",
    "    filter_str = (\n",
    "        f'resource.labels.job_name={job_name}'\n",
    "        f' resource.type=\"dataflow_step\"'\n",
    "        f' AND severity >= ERROR'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #This will only run if the user attempts to submit a file\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        #this will only run if what the user submitted is a file\n",
    "        if 'file' in request.files:\n",
    "            #this gets the file data\n",
    "            file = request.files['file']\n",
    "            #this aquires the name of the file\n",
    "            filename = secure_filename(file.filename)\n",
    "            if len(file.readlines()) == 0:\n",
    "                message = \"File has no data to process\"\n",
    "            else:\n",
    "                file.seek(0)\n",
    "                try:\n",
    "                    #this will only run if the file is a csv\n",
    "                    if filename.endswith('.csv'):\n",
    "                        blob = bucket.blob('data.csv')\n",
    "                        blob.upload_from_file(file)\n",
    "                        \n",
    "                        file.seek(0)\n",
    "                        total_records = len(file.readlines())\n",
    "                        \n",
    "                        table_id = request.form.getlist('checks')[0]\n",
    "                        SCHEMA = {}\n",
    "                        table_sch = []\n",
    "                        try:\n",
    "                            SchemaJob = client.get_table('model-craft-342921.testing.{}'.format(table_id))\n",
    "                            for s in SchemaJob.schema:\n",
    "                                new_dict = {}\n",
    "                                new_dict['name'] = s.name\n",
    "                                new_dict['type'] = s.field_type\n",
    "                                new_dict['mode'] = s.mode\n",
    "                                table_sch.append(new_dict)\n",
    "                            SCHEMA['fields'] = table_sch\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                        filename_helper = str(datetime.datetime.now())\n",
    "                        filename = \"LOG: \"+ filename_helper + \".txt\"\n",
    "                        try:\n",
    "                            #start = time.time()\n",
    "                            p = beam.Pipeline(options=beam_options)\n",
    "                            events  = (p | 'ReadData' >> beam.io.ReadFromText('gs://data_intake4062022/data.csv', skip_header_lines =1)\n",
    "                                   | 'Split' >> beam.Map(lambda x: x.split(','))\n",
    "                                    | 'format to dict2' >> beam.ParDo(formating(),table_sch) \n",
    "                                   | 'WriteToBigQuery2' >>  beam.io.gcp.bigquery.WriteToBigQuery(\n",
    "                                       'model-craft-342921:testing.{}'.format(table_id),\n",
    "                                       schema=SCHEMA,\n",
    "                                       write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,\n",
    "                                       insert_retry_strategy=beam.io.gcp.bigquery_tools.RetryStrategy.RETRY_NEVER,\n",
    "                                       method='STREAMING_INSERTS')\n",
    "                                    )\n",
    "                            (events[beam.io.gcp.bigquery.BigQueryWriteFn.FAILED_ROWS]\n",
    "                                    | \"Bad lines\" >> beam.io.WriteToText('gs://practice_error_logs/{}'.format(filename), shard_name_template = \"\")\n",
    "                            )\n",
    "                            \n",
    "                            result = p.run()\n",
    "                            result.wait_until_finish()\n",
    "                            \n",
    "                        except Exception as error:\n",
    "                            print('This was the error: ', error)\n",
    "                            message = \"Error setting up the data ingestion pipeline\"\n",
    "                            \n",
    "                        try:\n",
    "                            messages = []\n",
    "                            log_builder = {}\n",
    "                            for entry in logger.list_entries(filter_=filter_str):  # API call(s)\n",
    "                                message = entry.to_api_repr()['jsonPayload']['message']\n",
    "                                list_extract = message.replace(\"There were errors inserting to BigQuery. Will not retry. Errors were \",\"\")\n",
    "                                list_extract = list_extract.replace(\"'\",'\"')\n",
    "                                res = json.loads(list_extract)\n",
    "                                for i in range(0,len(res)):\n",
    "                                    log_builder = {}\n",
    "                                    log_builder['location'] = res[i]['errors'][0]['location']\n",
    "                                    log_builder['message'] = res[i]['errors'][0]['message']\n",
    "                                    messages.append(log_builder)\n",
    "                            \n",
    "                            blob = bucket1.blob(filename)\n",
    "                            blob.upload_from_string(str(messages))\n",
    "                            message = \"Data uploaded to the Bigquery\"\n",
    "                            \n",
    "                        except Exception as error:\n",
    "                            print('This was the error: ', error)\n",
    "                            message = \"Error getting logs\"\n",
    "                            \n",
    "                        try:\n",
    "                            blob = bucket2.blob(filename)\n",
    "                            downloaded_blob = blob.download_as_string()\n",
    "                            log_message = downloaded_blob.decode(\"utf-8\", \"ignore\")\n",
    "                            log_message =log_message.split('\\n')\n",
    "                            bad_row = []\n",
    "                            bad_json = []\n",
    "                            bad_input_data = {}\n",
    "                            for element in log_message:\n",
    "                                element = element.replace(\"'model-craft-342921:testing.Task3', \",'')\n",
    "                                element = element.replace('(','')\n",
    "                                element = element.replace(')','')\n",
    "                                element = element.replace(\"'\",'\"')\n",
    "                                bad_row.append(element)\n",
    "                            for index in range(0,len(bad_row)-1):\n",
    "                                bad_json.append(json.loads(bad_row[index]))\n",
    "                            bad_input_data['elements'] = bad_json\n",
    "                            \n",
    "                        except Exception as error:\n",
    "                            print('This was the error: ', error)\n",
    "                            message = \"Error setting up messaging\"\n",
    "                            \n",
    "                            #end = time.time()\n",
    "                            #Total_time = end - start\n",
    "                            #string = \"\"\"UPDATE `model-craft-342921.testing.Statics` SET Completion_time = '{}' WHERE Project_id = '{}'\"\"\".format(Total_time, job_name)\n",
    "                            #query_job = client.query(string)\n",
    "                            #query_job.result()\n",
    "                        \n",
    "                        try:\n",
    "                            p1 = beam.Pipeline(options=beam_options)\n",
    "                            events  = (p1 | 'ReadData' >> beam.io.ReadFromText('gs://error_messages4142022/{}'.format(filename))\n",
    "                                          | 'Process Messaging' >> beam.ParDo(process_message(),bad_input_data)\n",
    "                                            | 'Store Final Message' beam.io.WriteToText('gs://complete_message_4182022/{}'.format(filename), shard_name_template = \"\")\n",
    "                                      )\n",
    "                            result = p1.run()\n",
    "                            result.wait_until_finish()\n",
    "\n",
    "                        except Exception as error:\n",
    "                            print('This was the error: ', error)\n",
    "                            message = \"Error setting up the error formating pipeline\"\n",
    "\n",
    "                    #If the file is not a json or the csv this will run\n",
    "                    else:\n",
    "                        message = \"File type is not excepted\"\n",
    "                    #endif\n",
    "                except Exception as error:\n",
    "                    print('This was the error: ', error)\n",
    "                    message = \"There was an error in creating the request\"\n",
    "            #endif\n",
    "        #This will run if the submition is not a file type\n",
    "        elif 'file' not in request.files:\n",
    "            message = \"There was no file to upload\"\n",
    "        #endif\n",
    "    #endif\n",
    "\n",
    "    #this will render the template on the website\n",
    "    return render_template(\"front.html\", message = message, tables = tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
